{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Les imports & le code de base Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\neelp\\anaconda3\\lib\\site-packages (0.8.11)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from mediapipe) (3.5.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: numpy in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from mediapipe) (1.21.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\neelp\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\neelp\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neelp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sickitlearn (from versions: none)\n",
      "ERROR: No matching distribution found for sickitlearn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install mediapipe\n",
    "!pip install opencv-python\n",
    "!pip install pandas\n",
    "!pip install sickitlearn\n",
    "import mediapipe as mp  # Import mediapipe\n",
    "import cv2  # Import opencv\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic  # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-20.04\\home\\neelp\\user\\PROJET-CAPGEMINI\\stefreformvideo.ipynb Cellule 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mpose_landmarks, mp_holistic\u001b[39m.\u001b[39mPOSE_CONNECTIONS,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                                   mp_drawing\u001b[39m.\u001b[39mDrawingSpec(\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m                                       color\u001b[39m=\u001b[39m(\u001b[39m245\u001b[39m, \u001b[39m117\u001b[39m, \u001b[39m66\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m                                   mp_drawing\u001b[39m.\u001b[39mDrawingSpec(\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                                       color\u001b[39m=\u001b[39m(\u001b[39m245\u001b[39m, \u001b[39m66\u001b[39m, \u001b[39m230\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m                                   )\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mRaw Webcam Feed\u001b[39m\u001b[39m'\u001b[39m, image)\n\u001b[1;32m---> <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m10\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#W2sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "\n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                                  )\n",
    "\n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exporter les données\n",
    "\n",
    "### Préliminaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coords = 75 # nombre de points du corps + main gauche + main droite\n",
    "# for landmark in results.right_hand_landmarks.landmark:\n",
    "#     print(landmark, landmark.value)\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val),\n",
    "                  'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(\n",
    "        f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du mot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='mots/'\n",
    "mot = 'adresse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Cherche les fichiers à analyser en fonction du mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mots/adresse-00.mp4', 'mots/adresse-01.mp4', 'mots/adresse-02.mp4', 'mots/adresse-03.mp4', 'mots/adresse-04.mp4', 'mots/adresse-05.mp4', 'mots/adresse-06.mp4', 'mots/adresse-07.mp4', 'mots/adresse-08.mp4', 'mots/adresse-09.mp4', 'mots/adresse-10.mp4', 'mots/adresse-11.mp4', 'mots/adresse-12.mp4', 'mots/adresse-13.mp4', 'mots/adresse-14.mp4', 'mots/adresse-15.mp4', 'mots/adresse-16.mp4', 'mots/adresse-17.mp4', 'mots/adresse-18.mp4', 'mots/adresse-19.mp4']\n"
     ]
    }
   ],
   "source": [
    "fichier =[]\n",
    "for f in os.listdir(path):\n",
    "    file_name, file_ext = os.path.splitext(f)\n",
    "    testmot = file_name.split('-')\n",
    "    if (testmot[0]==mot):\n",
    "        # i=1\n",
    "        fichier += [path + file_name + file_ext]\n",
    "print(fichier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Parcourt les vidéos et exporte les coordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions.holistic' has no attribute 'FACE_CONNECTIONS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-20.04\\home\\neelp\\user\\PROJET-CAPGEMINI\\stefreformvideo.ipynb Cellule 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# 1. Draw face landmarks\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mface_landmarks, mp_holistic\u001b[39m.\u001b[39;49mFACE_CONNECTIONS, \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m110\u001b[39m,\u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                         )\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# 2. Right hand\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mright_hand_landmarks, mp_holistic\u001b[39m.\u001b[39mHAND_CONNECTIONS, \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m22\u001b[39m,\u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m44\u001b[39m,\u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-20.04/home/neelp/user/PROJET-CAPGEMINI/stefreformvideo.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe.python.solutions.holistic' has no attribute 'FACE_CONNECTIONS'"
     ]
    }
   ],
   "source": [
    "rang = 0\n",
    "for f in fichier :\n",
    "    #print(f)\n",
    "    cap = cv2.VideoCapture(f)\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "                \n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "                \n",
    "                # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "                \n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                # 1. Draw face landmarks\n",
    "                #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                #                        mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                #                        mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                #                        )\n",
    "                \n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                        )\n",
    "                # Export coordinates\n",
    "                pose_row =[]\n",
    "                right_hand_row=[]\n",
    "                left_hand_row=[]\n",
    "                try:\n",
    "                    # Extract Pose landmarks\n",
    "                    pose = results.pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                    #print(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]))\n",
    "                except : \n",
    "                    pass \n",
    "                try :\n",
    "                        # Extract hands landmarks\n",
    "                    right_hand = results.right_hand_landmarks.landmark\n",
    "                    right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    left_hand = results.left_hand_landmarks.landmark\n",
    "                    left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "                except :\n",
    "                    pass\n",
    "                    # Concate rows\n",
    "                row = pose_row + right_hand_row + left_hand_row\n",
    "                \n",
    "                # Append class name \n",
    "                row.insert(0, mot + format(rang))\n",
    "                \n",
    "                # Export to CSV\n",
    "                with open('coords.csv', mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(row) \n",
    "                                \n",
    "                cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else :\n",
    "                break\n",
    "    rang += 1\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "23\n",
      "25\n",
      "27\n",
      "23\n",
      "24\n",
      "22\n",
      "25\n",
      "21\n",
      "26\n",
      "18\n",
      "23\n",
      "25\n",
      "24\n",
      "21\n",
      "19\n",
      "24\n",
      "23\n",
      "23\n",
      "23.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "count=0\n",
    "for f in fichier:\n",
    "    cap = cv2.VideoCapture(f)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    count=count+length\n",
    "    print( length )\n",
    "moy=count/20\n",
    "print(moy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture('mots/adresse-01.mp4')\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(\"image2/image\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames\n",
    "sec = 0\n",
    "frameRate = 0.035 #//it will capture image in each 0.5 second\n",
    "count=1\n",
    "success = getFrame(sec)\n",
    "while success:\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success = getFrame(sec)\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from os.path import isfile, join\n",
    "# pathIn= './images/testing/'\n",
    "# pathOut = 'video.avi'\n",
    "# fps = 0.5\n",
    "# frame_array = []\n",
    "# files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "# #for sorting the file names properly\n",
    "# files.sort(key = lambda x: x[5:-4])\n",
    "# files.sort()\n",
    "# frame_array = []\n",
    "# files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "# #for sorting the file names properly\n",
    "# files.sort(key = lambda x: x[5:-4])\n",
    "# for i in range(len(files)):\n",
    "#     filename=pathIn + files[i]\n",
    "#     #reading each files\n",
    "#     img = cv2.imread(filename)\n",
    "#     height, width, layers = img.shape\n",
    "#     size = (width,height)\n",
    "    \n",
    "#     #inserting the frames into an image array\n",
    "#     frame_array.append(img)\n",
    "# out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "# for i in range(len(frame_array)):\n",
    "#     # writing to a image array\n",
    "#     out.write(frame_array[i])\n",
    "# out.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "pathIn= 'image2/'\n",
    "pathOut = 'video2.mp4'\n",
    "fps = 10\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "for i in range(len(files)):\n",
    "    filename=pathIn + files[i]\n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"video2.mp4\")\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dbdba21da6ecf7744d14d63468dc9a07f24541ecd108de55ef47192e3ab8e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
